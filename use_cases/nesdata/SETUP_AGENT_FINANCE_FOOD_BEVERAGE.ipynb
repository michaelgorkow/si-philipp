{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "IMPORTS"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "from snowflake.snowpark.functions import col\n",
    "from snowflake.snowpark import types as T\n",
    "from snowflake.core import Root\n",
    "from snowflake.cortex import Complete\n",
    "from service_generation import create_cortex_search_service\n",
    "session = get_active_session()\n",
    "root = Root(get_active_session())\n",
    "\n",
    "# Document Generation\n",
    "import doc_generation\n",
    "doc_generation.generate_demo_documents(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66bee02-de2d-4c96-92dc-2a683e8be305",
   "metadata": {
    "collapsed": false,
    "name": "OVERVIEW"
   },
   "source": [
    "# Cortex Agents\n",
    "In this notebook you will setup multiple Cortex Search and Cortex Analyst Services which will be used by Cortex Agents to answer user queries on unstructured and structured data.\n",
    "![text](https://github.com/michaelgorkow/snowflake_cortex_agents_demo/blob/main/resources/cortex_agents_notebook_small.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cda5f3-3dc6-4609-bf2d-12d114adb9af",
   "metadata": {
    "collapsed": false,
    "name": "CORTEX_SEARCH1"
   },
   "source": [
    "# Setup the Cortex Search Service [Unstructured Data]\n",
    "\n",
    "We have some PDF documents in our stage **DOCUMENTS** that we want business users to be able to ask questions about.  \n",
    "To achieve this, we need to extract the contents of the PDF files and make them searchable.\n",
    "\n",
    "## Extracting Content from PDF Files\n",
    "\n",
    "### [`PARSE_DOCUMENT`](https://docs.snowflake.com/en/sql-reference/functions/parse_document-snowflake-cortex)  \n",
    "This function returns the extracted content from a document on a Snowflake stage as an **OBJECT** that contains JSON-encoded objects as strings.  \n",
    "\n",
    "It supports two types of extractions:  \n",
    "- **Optical Character Recognition (OCR)**  \n",
    "- **Layout Extraction**  \n",
    "\n",
    "### [`SPLIT_TEXT_RECURSIVE_CHARACTER`](https://docs.snowflake.com/en/sql-reference/functions/split_text_recursive_character-snowflake-cortex)  \n",
    "The `SPLIT_TEXT_RECURSIVE_CHARACTER` function splits a string into shorter strings recursively. It is useful for preprocessing text to be used with text embedding or search indexing functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3cb35b-78ee-4091-97c2-0b05443d8e52",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "CORTEX_SEARCH2"
   },
   "outputs": [],
   "source": [
    "-- List documents in stage\n",
    "SELECT * FROM DIRECTORY('@DOCUMENTS');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0d2d82-16f6-4552-bc50-d56f91ce30d3",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "CORTEX_SEARCH3"
   },
   "outputs": [],
   "source": [
    "-- Layout extraction for PDF documents\n",
    "CREATE TABLE IF NOT EXISTS _UNSTR_RAW_DOCUMENTS_MARKETING_CAMPAIGNS AS\n",
    "SELECT \n",
    "    RELATIVE_PATH,\n",
    "    TO_VARCHAR (\n",
    "        SNOWFLAKE.CORTEX.PARSE_DOCUMENT (\n",
    "            '@DOCUMENTS',\n",
    "            RELATIVE_PATH,\n",
    "            {'mode': 'LAYOUT'} ):content\n",
    "        ) AS EXTRACTED_LAYOUT \n",
    "FROM \n",
    "    DIRECTORY('@DOCUMENTS')\n",
    "WHERE\n",
    "    startswith(RELATIVE_PATH, 'marketing_campaigns/');\n",
    "\n",
    "SELECT * FROM _UNSTR_RAW_DOCUMENTS_MARKETING_CAMPAIGNS;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ec3abd-9a67-4d63-a7cb-d22196990390",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "CORTEX_SEARCH4"
   },
   "outputs": [],
   "source": [
    "-- Create chunks from extracted content\n",
    "CREATE OR REPLACE TABLE _UNSTR_CHUNKED_DOCUMENTS_MARKETING_CAMPAIGNS AS\n",
    "SELECT\n",
    "   RELATIVE_PATH,\n",
    "   GET_PRESIGNED_URL(@DOCUMENTS, RELATIVE_PATH, 604800) AS URL,\n",
    "   c.INDEX::INTEGER AS CHUNK_INDEX,\n",
    "   c.value::TEXT AS CHUNK_TEXT\n",
    "FROM\n",
    "   _UNSTR_RAW_DOCUMENTS_MARKETING_CAMPAIGNS,\n",
    "   LATERAL FLATTEN( input => SNOWFLAKE.CORTEX.SPLIT_TEXT_RECURSIVE_CHARACTER (\n",
    "      EXTRACTED_LAYOUT,\n",
    "      'markdown',\n",
    "      4000,\n",
    "      0,\n",
    "      ['\\n\\n', '\\n', ' ', '']\n",
    "   )) c;\n",
    "\n",
    "SELECT * FROM _UNSTR_CHUNKED_DOCUMENTS_MARKETING_CAMPAIGNS;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c651cd6-a275-4a07-9b85-52a1554937fa",
   "metadata": {
    "language": "sql",
    "name": "CORTEX_SEARCH5"
   },
   "outputs": [],
   "source": [
    "-- Create a Cortex Search Service for Annual Reports\n",
    "CREATE OR REPLACE CORTEX SEARCH SERVICE SEARCH_MARKETING_CAMPAIGNS\n",
    "  ON CHUNK_TEXT\n",
    "  ATTRIBUTES RELATIVE_PATH, CHUNK_INDEX\n",
    "  WAREHOUSE = COMPUTE_WH\n",
    "  TARGET_LAG = '1 hour'\n",
    "  EMBEDDING_MODEL = 'snowflake-arctic-embed-l-v2.0'\n",
    "AS (\n",
    "  SELECT\n",
    "      CHUNK_TEXT,\n",
    "      RELATIVE_PATH,\n",
    "      CHUNK_INDEX,\n",
    "      URL\n",
    "  FROM _UNSTR_CHUNKED_DOCUMENTS_MARKETING_CAMPAIGNS\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90683ce5-b523-4c70-bfaf-3b90652ceefc",
   "metadata": {
    "language": "python",
    "name": "CORTEX_SEARCH6"
   },
   "outputs": [],
   "source": [
    "# Create additional search services\n",
    "create_cortex_search_service(session, 'product_specifications')\n",
    "create_cortex_search_service(session, 'regional_market_reports')\n",
    "create_cortex_search_service(session, 'financial_operations_reports')\n",
    "create_cortex_search_service(session, 'customer_contracts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f8ca07-db9b-4cf5-b2a5-e5a3e030aaf0",
   "metadata": {
    "collapsed": false,
    "name": "CORTEX_SEARCH7"
   },
   "source": [
    "### [Optional] Test Your Service in a Simple RAG Pipeline  \n",
    "\n",
    "In this small example, we **combine Cortex Search with Cortex LLMs** to generate a response from context—also known as **Retrieval-Augmented Generation (RAG)**.  \n",
    "This approach enhances responses by retrieving relevant data before generating an answer, improving accuracy and contextual relevance. 🚀  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e07ffc-0874-422b-a439-dacdaab98585",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "CORTEX_SEARCH8"
   },
   "outputs": [],
   "source": [
    "question = 'Which marketing campaigns targeted the Chocolate category and what were the sales results?'\n",
    "\n",
    "# Fetch service\n",
    "my_service = (root\n",
    "  .databases[\"CORTEX_AGENTS_DEMO\"]\n",
    "  .schemas[\"FINANCE_FOOD_BEVERAGE\"]\n",
    "  .cortex_search_services[\"SEARCH_MARKETING_CAMPAIGNS\"]\n",
    ")\n",
    "\n",
    "# Query service\n",
    "resp = my_service.search(\n",
    "  query=question,\n",
    "  columns=[\"CHUNK_INDEX\", \"CHUNK_TEXT\", \"RELATIVE_PATH\", \"URL\"],\n",
    "  limit=1,\n",
    "  experimental={'returnConfidenceScores':True}\n",
    ")\n",
    "resp = resp.results[0]\n",
    "\n",
    "st.info(f'**File:** {resp[\"RELATIVE_PATH\"]}\\n\\n **Source:**\\n\\n {resp[\"URL\"]}\\n\\n {resp[\"CHUNK_TEXT\"]}')\n",
    "\n",
    "# Generate Response\n",
    "model = 'mistral-large2'\n",
    "prompt = f\"{question} Answer based on the provided context: {resp['CHUNK_TEXT']}\"\n",
    "response = Complete(model, prompt).strip()\n",
    "\n",
    "st.info(f'**LLM Response:**\\n\\n**{response}**')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00717c52-d652-48c9-be0b-1aaf5d0e2748",
   "metadata": {
    "collapsed": false,
    "name": "CORTEX_ANALYST1"
   },
   "source": [
    "# Setup the Cortex Analyst Service [Structured Data]  \n",
    "\n",
    "We generate a realistic looking financial dataset for a food and beverage company that users will be able to **query in natural language**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6683f336-9343-4fe5-8d14-faad35a4c725",
   "metadata": {
    "language": "python",
    "name": "CORTEX_ANALYST2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "def generate_financial_dataset():\n",
    "    \"\"\"Generate a realistic financial dataset for food and beverage company\"\"\"\n",
    "    \n",
    "    categories = {\n",
    "        'Coffee': ['NesKafe Classic', 'NesKafe Gold', 'NesKafe Decaf', 'NesKafe Instant',\n",
    "                  'NesKafe Cappuccino', 'NesKafe Latte', 'NesKafe Mocha'],\n",
    "        'Water': ['PureLife Natural', 'PureLife Sparkling', 'PureLife Flavored', \n",
    "                 'AquaFlow Premium', 'SpringSource Mountain', 'CrystalClear Pure'],\n",
    "        'Chocolate': ['ChocoBars Dark', 'ChocoBars Milk', 'ChocoBars White', 'ChocoBars Almond',\n",
    "                     'SweetTreats Original', 'SweetTreats Caramel', 'ChocoWafers Crispy',\n",
    "                     'CreamyBites Hazelnut', 'DeluxeChoc Premium'],\n",
    "        'Baby Food': ['BabyFirst Formula', 'BabyFirst Organic', 'BabyFirst Cereal', \n",
    "                     'TinyTots Puree', 'LittleOnes Snacks', 'InfantCare Plus'],\n",
    "        'Dairy': ['CreamyDelight Vanilla', 'CreamyDelight Chocolate', 'CreamyDelight Strawberry',\n",
    "                 'FrozenJoy Cookies', 'FrozenJoy Mint', 'PremiumScoop Deluxe'],\n",
    "        'Cereals': ['MorningCrunch Honey', 'MorningCrunch Chocolate', 'HealthyStart Oats',\n",
    "                   'FiberPlus Original', 'KidsChoice Fruity'],\n",
    "        'Pet Care': ['PetLove Dry Food', 'PetLove Wet Food', 'PetLove Treats', 'PetCare Premium']\n",
    "    }\n",
    "    \n",
    "    products_data = []\n",
    "    for category, products in categories.items():\n",
    "        for i, product in enumerate(products, 1):\n",
    "            products_data.append({\n",
    "                'PRODUCT_ID': len(products_data) + 1,\n",
    "                'PRODUCT_NAME': product,\n",
    "                'CATEGORY': category,\n",
    "                'UNIT_COST': round(random.uniform(0.5, 15.0), 2),\n",
    "                'UNIT_PRICE': round(random.uniform(1.0, 25.0), 2)\n",
    "            })\n",
    "    \n",
    "    products_df = pd.DataFrame(products_data)\n",
    "    \n",
    "    # 2. CUSTOMERS TABLE (High cardinality - customer names)\n",
    "    customer_types = ['Supermarket', 'Convenience Store', 'Hypermarket', 'Online Retailer', 'Distributor']\n",
    "    regions = ['North America', 'Europe', 'Asia Pacific', 'Latin America', 'Middle East & Africa']\n",
    "    \n",
    "    customer_names = [\n",
    "        # Supermarkets\n",
    "        'FreshMart Downtown', 'FreshMart Central', 'FreshMart Plaza', 'GroceryWorld Main',\n",
    "        'GroceryWorld Express', 'SuperShop Premium', 'SuperShop Local', 'MegaStore Alpha',\n",
    "        'MegaStore Beta', 'MegaStore Gamma', 'QuickBuy Central', 'QuickBuy Corner',\n",
    "        \n",
    "        # Hypermarkets\n",
    "        'HyperMall North', 'HyperMall South', 'HyperMall East', 'GiantStore Complex',\n",
    "        'GiantStore Plaza', 'UltraMart Mega', 'UltraMart Super',\n",
    "        \n",
    "        # Online Retailers\n",
    "        'E-Commerce Hub', 'Digital Grocery Co', 'Online Fresh Ltd', 'WebMart Express',\n",
    "        'VirtualStore Pro', 'ClickAndBuy Solutions',\n",
    "        \n",
    "        # Distributors\n",
    "        'Regional Dist. Corp', 'National Supply Chain', 'Metro Distribution', \n",
    "        'Premium Wholesale Ltd', 'Global Trade Partners', 'Continental Suppliers',\n",
    "        \n",
    "        # International\n",
    "        'EuroMart Berlin', 'EuroMart Paris', 'AsiaFresh Tokyo', 'AsiaFresh Seoul',\n",
    "        'LatinMarket Mexico', 'LatinMarket Brazil', 'AfricaTrade Lagos', 'AfricaTrade Cairo'\n",
    "    ]\n",
    "    \n",
    "    customers_data = []\n",
    "    for i, name in enumerate(customer_names, 1):\n",
    "        customers_data.append({\n",
    "            'CUSTOMER_ID': i,\n",
    "            'CUSTOMER_NAME': name,\n",
    "            'CUSTOMER_TYPE': random.choice(customer_types),\n",
    "            'REGION': random.choice(regions),\n",
    "            'CREDIT_LIMIT': random.choice([50000, 100000, 250000, 500000, 1000000])\n",
    "        })\n",
    "    \n",
    "    customers_df = pd.DataFrame(customers_data)\n",
    "    \n",
    "    # 3. TIME PERIODS TABLE\n",
    "    start_date = datetime(2021, 1, 1)\n",
    "    time_periods = []\n",
    "    \n",
    "    for i in range(48):  # 24 months\n",
    "        current_date = start_date + timedelta(days=30*i)\n",
    "        time_periods.append({\n",
    "            'PERIOD_ID': i + 1,\n",
    "            'YEAR': current_date.year,\n",
    "            'MONTH': current_date.month,\n",
    "            'QUARTER': f\"Q{(current_date.month-1)//3 + 1}\",\n",
    "            'MONTH_NAME': current_date.strftime('%B'),\n",
    "            'DATE': current_date.strftime('%Y-%m-%d')\n",
    "        })\n",
    "    \n",
    "    time_periods_df = pd.DataFrame(time_periods)\n",
    "    \n",
    "    # 4. SALES TRANSACTIONS TABLE\n",
    "    sales_data = []\n",
    "    transaction_id = 1\n",
    "    \n",
    "    for period in range(1, 49):  # 24 months\n",
    "        # Generate different number of transactions per month\n",
    "        num_transactions = random.randint(800, 1200)\n",
    "        \n",
    "        for _ in range(num_transactions):\n",
    "            customer_id = random.randint(1, len(customers_df))\n",
    "            product_id = random.randint(1, len(products_df))\n",
    "            quantity = random.randint(10, 1000)\n",
    "            \n",
    "            # Get product info for calculations\n",
    "            product_info = products_df[products_df['PRODUCT_ID'] == product_id].iloc[0]\n",
    "            unit_price = product_info['UNIT_PRICE']\n",
    "            unit_cost = product_info['UNIT_COST']\n",
    "            \n",
    "            # Add some price variation\n",
    "            actual_price = unit_price * random.uniform(0.9, 1.1)\n",
    "            revenue = quantity * actual_price\n",
    "            cost = quantity * unit_cost\n",
    "            \n",
    "            sales_data.append({\n",
    "                'TRANSACTION_ID': transaction_id,\n",
    "                'CUSTOMER_ID': customer_id,\n",
    "                'PRODUCT_ID': product_id,\n",
    "                'PERIOD_ID': period,\n",
    "                'QUANTITY_SOLD': quantity,\n",
    "                'UNIT_PRICE': round(actual_price, 2),\n",
    "                'TOTAL_REVENUE': round(revenue, 2),\n",
    "                'TOTAL_COST': round(cost, 2),\n",
    "                'GROSS_PROFIT': round(revenue - cost, 2)\n",
    "            })\n",
    "            transaction_id += 1\n",
    "    \n",
    "    sales_df = pd.DataFrame(sales_data)\n",
    "    \n",
    "    # 5. MARKETING CAMPAIGNS TABLE\n",
    "    campaigns_data = [\n",
    "        {'campaign_id': 1, 'campaign_name': 'Coffee Lovers Special', 'category': 'Coffee', \n",
    "         'start_period': 3, 'end_period': 5, 'budget': 500000, 'discount_percent': 15},\n",
    "        {'campaign_id': 2, 'campaign_name': 'Summer Hydration', 'category': 'Water', \n",
    "         'start_period': 6, 'end_period': 8, 'budget': 750000, 'discount_percent': 10},\n",
    "        {'campaign_id': 3, 'campaign_name': 'Back to School', 'category': 'Cereals', \n",
    "         'start_period': 8, 'end_period': 9, 'budget': 400000, 'discount_percent': 20},\n",
    "        {'campaign_id': 4, 'campaign_name': 'Holiday Treats', 'category': 'Chocolate', \n",
    "         'start_period': 11, 'end_period': 12, 'budget': 1000000, 'discount_percent': 25},\n",
    "        {'campaign_id': 5, 'campaign_name': 'New Year Health', 'category': 'Baby Food', \n",
    "         'start_period': 13, 'end_period': 14, 'budget': 300000, 'discount_percent': 12},\n",
    "        {'campaign_id': 6, 'campaign_name': 'Spring Refresh', 'category': 'Dairy', \n",
    "         'start_period': 15, 'end_period': 17, 'budget': 600000, 'discount_percent': 18},\n",
    "        {'campaign_id': 7, 'campaign_name': 'Pet Love Month', 'category': 'Pet Care', \n",
    "         'start_period': 18, 'end_period': 18, 'budget': 200000, 'discount_percent': 30}\n",
    "    ]\n",
    "    \n",
    "    campaigns_df = pd.DataFrame(campaigns_data)\n",
    "    campaigns_df.columns = [col.upper() for col in campaigns_df.columns]\n",
    "    \n",
    "    return {\n",
    "        'products': products_df,\n",
    "        'customers': customers_df,\n",
    "        'time_periods': time_periods_df,\n",
    "        'sales': sales_df,\n",
    "        'campaigns': campaigns_df\n",
    "    }\n",
    "\n",
    "# Generate the dataset\n",
    "dataset = generate_financial_dataset()\n",
    "\n",
    "# Save to Snowflake\n",
    "products_df = session.write_pandas(df=dataset['products'], table_name='PRODUCTS', overwrite=True, auto_create_table=True)\n",
    "customers_df = session.write_pandas(df=dataset['customers'], table_name='CUSTOMERS', overwrite=True, auto_create_table=True)\n",
    "time_periods_df = session.write_pandas(df=dataset['time_periods'], table_name='TIME_PERIODS', overwrite=True, auto_create_table=True)\n",
    "time_periods_df = time_periods_df.with_column(\"DATE\", col(\"DATE\").cast(T.DateType()))\n",
    "time_periods_df.write.mode(\"overwrite\").save_as_table('TIME_PERIODS', mode='overwrite')\n",
    "campaigns_df = session.write_pandas(df=dataset['campaigns'], table_name='CAMPAIGNS', overwrite=True, auto_create_table=True)\n",
    "sales_df = session.write_pandas(df=dataset['sales'], table_name='SALES', overwrite=True, auto_create_table=True)\n",
    "\n",
    "# Display sample data\n",
    "for table_name, df in dataset.items():\n",
    "    st.subheader(f\"\\n{table_name.upper()}\")\n",
    "    st.dataframe(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352d9b4d-9c34-4e91-9cc6-caa60b231b2f",
   "metadata": {
    "collapsed": false,
    "name": "CORTEX_ANALYST4"
   },
   "source": [
    "# Dynamic Literal Retrieval with Cortex Analyst\n",
    "\n",
    "Business users may not have detailed knowledge of how data is stored in Snowflake.  \n",
    "Instead of ingesting all possible values of a column into **Cortex Analyst**, we will use **dynamic literal retrieval** via the [Cortex Search Integration](https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-analyst/cortex-analyst-search-integration).\n",
    "\n",
    "## How It Works  \n",
    "When a user asks a question about their **sales** that requires the `PRODUCT_NAME`, `CUSTOMER_NAME`, `CAMPAIGN_NAME` column, **Cortex Analyst** will:  \n",
    "1. Retrieve the relevant literal dynamically from **Cortex Search**  \n",
    "2. Use it for **SQL generation**  \n",
    "\n",
    "This approach ensures efficient and accurate query generation without preloading all possible values into Cortex Analyst.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837aa585-3963-4767-9f6e-df919c4faf6a",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "CORTEX_ANALYST5"
   },
   "outputs": [],
   "source": [
    "CREATE CORTEX SEARCH SERVICE IF NOT EXISTS _ANALYST_PRODUCT_NAME_SEARCH\n",
    "  ON PRODUCT_NAME\n",
    "  WAREHOUSE = COMPUTE_WH\n",
    "  TARGET_LAG = '1 hour'\n",
    "  EMBEDDING_MODEL = 'snowflake-arctic-embed-l-v2.0'\n",
    "AS (\n",
    "  SELECT\n",
    "      DISTINCT PRODUCT_NAME\n",
    "  FROM PRODUCTS\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251cec9e-4070-4fcc-af17-11747b58b0c7",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "CORTEX_ANALYST6"
   },
   "outputs": [],
   "source": [
    "CREATE CORTEX SEARCH SERVICE IF NOT EXISTS _ANALYST_CUSTOMER_NAME_SEARCH\n",
    "  ON CUSTOMER_NAME\n",
    "  WAREHOUSE = COMPUTE_WH\n",
    "  TARGET_LAG = '1 hour'\n",
    "  EMBEDDING_MODEL = 'snowflake-arctic-embed-l-v2.0'\n",
    "AS (\n",
    "  SELECT\n",
    "      DISTINCT CUSTOMER_NAME,\n",
    "  FROM CUSTOMERS\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d822ae0c-101f-4f36-9252-b7e13134b3f1",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "CORTEX_ANALYST7"
   },
   "outputs": [],
   "source": [
    "CREATE CORTEX SEARCH SERVICE IF NOT EXISTS _ANALYST_CAMPAIGN_SEARCH\n",
    "  ON CAMPAIGN_NAME\n",
    "  WAREHOUSE = COMPUTE_WH\n",
    "  TARGET_LAG = '1 hour'\n",
    "  EMBEDDING_MODEL = 'snowflake-arctic-embed-l-v2.0'\n",
    "AS (\n",
    "  SELECT\n",
    "      DISTINCT CAMPAIGN_NAME,\n",
    "  FROM CAMPAIGNS\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bf508c-613d-41db-a87d-d4212ce69836",
   "metadata": {
    "collapsed": false,
    "name": "CORTEX_ANALYST8"
   },
   "source": [
    "### [Optional] Test Literal Retrievals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ff86b7-a46e-4faf-b6e6-7ed32a2b9a5b",
   "metadata": {
    "language": "python",
    "name": "CORTEX_ANALYST9"
   },
   "outputs": [],
   "source": [
    "question = 'What was the over impact of the sumer hydration campaign?'\n",
    "\n",
    "# Fetch service\n",
    "my_service = (root\n",
    "  .databases[\"CORTEX_AGENTS_DEMO\"]\n",
    "  .schemas[\"FINANCE_FOOD_BEVERAGE\"]\n",
    "  .cortex_search_services[\"_ANALYST_CAMPAIGN_SEARCH\"]\n",
    ")\n",
    "\n",
    "# Query service\n",
    "resp = my_service.search(\n",
    "  query=question,\n",
    "  columns=[\"CAMPAIGN_NAME\"],\n",
    "  limit=1\n",
    ")\n",
    "resp = resp.results[0]\n",
    "\n",
    "st.info(f'**Search Results: {resp[\"CAMPAIGN_NAME\"]}**')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d536d7d-2d40-43e3-b0ce-b6e71d21fdd3",
   "metadata": {
    "language": "python",
    "name": "CORTEX_ANALYST10"
   },
   "outputs": [],
   "source": [
    "question = 'What was the revenue per week for my customer supershop local?'\n",
    "\n",
    "# Fetch service\n",
    "my_service = (root\n",
    "  .databases[\"CORTEX_AGENTS_DEMO\"]\n",
    "  .schemas[\"FINANCE_FOOD_BEVERAGE\"]\n",
    "  .cortex_search_services[\"_ANALYST_CUSTOMER_NAME_SEARCH\"]\n",
    ")\n",
    "\n",
    "# Query service\n",
    "resp = my_service.search(\n",
    "  query=question,\n",
    "  columns=[\"CUSTOMER_NAME\"],\n",
    "  limit=1\n",
    ")\n",
    "\n",
    "for r in resp.results:\n",
    "    st.info(r['CUSTOMER_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff6c8aa-0c58-4462-b54f-1d98e0349e93",
   "metadata": {
    "language": "python",
    "name": "CORTEX_ANALYST11"
   },
   "outputs": [],
   "source": [
    "question = 'What was the revenue for pure life products?'\n",
    "\n",
    "# Fetch service\n",
    "my_service = (root\n",
    "  .databases[\"CORTEX_AGENTS_DEMO\"]\n",
    "  .schemas[\"FINANCE_FOOD_BEVERAGE\"]\n",
    "  .cortex_search_services[\"_ANALYST_PRODUCT_NAME_SEARCH\"]\n",
    ")\n",
    "\n",
    "# Query service\n",
    "resp = my_service.search(\n",
    "  query=question,\n",
    "  columns=[\"PRODUCT_NAME\"],\n",
    "  limit=3\n",
    ")\n",
    "\n",
    "for r in resp.results:\n",
    "    st.info(r['PRODUCT_NAME'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb814df-fa76-45af-bfaf-add22a17c61f",
   "metadata": {
    "collapsed": false,
    "name": "CORTEX_ANALYST12"
   },
   "source": [
    "# Explore the Semantic Model in the Snowflake UI  \n",
    "\n",
    "With our data available in **Snowflake** and the **Search Services** set up, it's time to explore the **native Semantic Model Generator** in **Snowsight**.  \n",
    "![text](https://github.com/michaelgorkow/snowflake_cortex_agents_demo/blob/main/resources/semantic_model_ui.png?raw=true)\n",
    "\n",
    "## Why Do You Need a Semantic Model?  \n",
    "\n",
    "**Cortex Analyst** allows users to query **Snowflake** data using **natural language**. However, business users often use terminology that does not align with the database schema.  \n",
    "\n",
    "### The Problem  \n",
    "- Users specify **domain-specific business terms** in their questions  \n",
    "- Underlying data is stored using **technical abbreviations**  \n",
    "- Example:  \n",
    "  - **\"CUST\"** is used for **customers**  \n",
    "  - **Schema lacks semantic context**, making queries harder to interpret  \n",
    "\n",
    "### The Solution: Semantic Models  \n",
    "Semantic models **map business terminology to database schemas** and provide **contextual meaning**.  \n",
    "\n",
    "#### Example  \n",
    "When a user asks:  \n",
    "🗣️ *\"Total revenue last month\"*  \n",
    "\n",
    "The **semantic model** can:  \n",
    "✅ Define **\"revenue\"** as **net revenue**  \n",
    "✅ Define **\"last month\"** as **the previous calendar month**  \n",
    "\n",
    "This mapping helps **Cortex Analyst** understand **user intent** and generate **accurate answers**.  \n",
    "\n",
    "🔗 More details can be found in the [Semantic Model Specification](https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-analyst/semantic-model-spec).  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "",
   "authorId": "61864603178",
   "authorName": "",
   "lastEditTime": 1751505792199,
   "notebookId": "65obtk3lxfkkssuka47q",
   "sessionId": "42884bf1-ffeb-4cc8-8f91-9dd28e34bd7f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
